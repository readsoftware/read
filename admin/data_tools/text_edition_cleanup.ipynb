{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#add parent dir to module search path to find readQueryCursor module\n",
    "sys.path.insert(0,os.path.dirname(os.getcwd()))\n",
    "#print(sys.path)\n",
    "import module.readQueryCursor as rqc\n",
    "import module.readStatistics as rsh\n",
    "import module.readLinkMaintenance as rlm\n",
    "\n",
    "dbname = 'testdb'\n",
    "outputFormat = 'csv'\n",
    "conf = rqc.readConnConfig.copy()\n",
    "conf['database'] = dbname\n",
    "conf['user'] = os.getenv('POSTGRES_USER')\n",
    "conf['password'] = os.getenv('POSTGRES_PASSWORD')\n",
    "myRQC = rqc.ReadQueryCursor(conf)\n",
    "\n",
    "# set default connection for ReadStatsHelper\n",
    "rsh.setReadStatsConnParameter(key='database', value=dbname)\n",
    "rsh.setReadStatsConnParameter(key='user', value=conf['user'])\n",
    "rsh.setReadStatsConnParameter(key='password', value=conf['password'])\n",
    "myRSH = rsh.ReadStatisticsHelper(myRQC)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deleteEntities(tableName = None, prefix = None, entIDs = None):\n",
    "  '''\n",
    "  Mark for delete all entities tableName table with an prefix_id in entIDs\n",
    "  '''\n",
    "  if not isinstance(entIDs, np.ndarray) or len(entIDs) == 0 or tableName == None or prefix == None:\n",
    "    print(f\"aborting delete of {tableName} with ids {entIDs}\")\n",
    "    return None\n",
    "  entCnt = len(entIDs)\n",
    "  owneridColLabel = prefix + \"_owner_id\"\n",
    "  visIDsColLabel = prefix + \"_visibility_ids\"\n",
    "  pkColLabel = prefix + \"_id\"\n",
    "  updCnt = 0\n",
    "  for id in entIDs:\n",
    "    myRQC.update(tableName,{owneridColLabel:\"1\",visIDsColLabel : \"{\" + \"5}\"},{pkColLabel:str(id)})\n",
    "    #print(\"update query = \",myRQC.getQuery())\n",
    "    if myRQC.getError():\n",
    "      print(f\"query to mark {tableName} entity id({id}) for delete failed\", myRQC.getError())\n",
    "      return myRQC.getError()\n",
    "    else:\n",
    "      updCnt += 1\n",
    "  if updCnt != entCnt:\n",
    "    return f\"result count {updCnt} did not equal count requested {entCnt}\"\n",
    "  return f\"Success: {entCnt} {tableName}s marked for delete\"\n",
    "\n",
    "\n",
    "def deleteTexts(txtIDs = None):\n",
    "  return deleteEntities('text','txt',txtIDs)\n",
    "\n",
    "def deleteText(txtID):\n",
    "  return deleteTexts([txtID])\n",
    "\n",
    "\n",
    "def deleteTextMetadatas(tmdIDs = None):\n",
    "  return deleteEntities('textmetadata','tmd',tmdIDs)\n",
    "\n",
    "def deleteTextMetadata(tmdID):\n",
    "  return deleteTextMetadatas([tmdID])\n",
    "\n",
    "\n",
    "def deleteEditions(ednIDs = None):\n",
    "  return deleteEntities('edition','edn',ednIDs)\n",
    "\n",
    "def deleteEdition(ednID):\n",
    "  return deleteEditions([ednID])\n",
    "\n",
    "\n",
    "def deleteSequences(seqIDs = None):\n",
    "  return deleteEntities('sequence','seq',seqIDs)\n",
    "\n",
    "def deleteSequence(seqID):\n",
    "  return deleteSequences([seqID])\n",
    "\n",
    "\n",
    "def deleteSyllableClusters(sclIDs = None):\n",
    "  return deleteEntities('syllablecluster','scl',sclIDs)\n",
    "\n",
    "def deleteSyllableCluster(sclID):\n",
    "  return deleteSyllableClusters([sclID])\n",
    "\n",
    "\n",
    "def deleteSegments(segIDs = None):\n",
    "  return deleteEntities('segment','seg',segIDs)\n",
    "\n",
    "def deleteSegment(segID):\n",
    "  return deleteSegments([segID])\n",
    "\n",
    "\n",
    "def deleteTokens(tokIDs = None):\n",
    "  return deleteEntities('token','tok',tokIDs)\n",
    "\n",
    "def deleteToken(tokID):\n",
    "  return deleteTokens([tokID])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Find active texts that have 'to delete' in title or invNo or no title\n",
    "'''\n",
    "queryFindTextToDelete = \\\n",
    "\" SELECT txt_id, txt_owner_id, edn_owner_id, txt_title, txt_ckn, edn_id, edn_description \\\n",
    "  FROM text \\\n",
    "    LEFT JOIN edition ON edn_text_id = txt_id \\\n",
    "  WHERE txt_owner_id > 1 \\\n",
    "    AND (txt_title ilike '%delete%' OR txt_ckn ilike '%delete%' OR txt_title IS NULL) \\\n",
    "  ORDER BY txt_owner_id,txt_id;\"\n",
    "myRQC.query(queryFindTextToDelete)\n",
    "dfDelTexts = pd.DataFrame(myRQC.getAllResults(), columns=myRQC.getColumnNames())\n",
    "toDelTxtIDs = []\n",
    "if 'txt_id' in dfDelTexts.columns:\n",
    "  toDelTxtIDs = pd.unique(sorted(list(dfDelTexts['txt_id'])))\n",
    "if len(toDelTxtIDs) > 0:\n",
    "  myRSH.saveDataFrame(dfDelTexts,\n",
    "                      outdir='output', \n",
    "                      filename=f\"texts_ready_to_delete{dbname}\",\n",
    "                      extType=outputFormat)\n",
    "  print(f\"Marking for delete text ids {toDelTxtIDs}\")\n",
    "#  deleteTexts(toDelTxtIDs)\n",
    "else:\n",
    "  print(\"No texts to process\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Find active textmetadata of marked for delete text\n",
    "'''\n",
    "queryFindTextMetadataToDelete = \\\n",
    "\" SELECT tmd_id, txt_id, tmd_owner_id, txt_owner_id \\\n",
    "  FROM textmetadata \\\n",
    "   LEFT JOIN text on tmd_text_id = txt_id \\\n",
    "  WHERE txt_owner_id = 1;\"\n",
    "myRQC.query(queryFindTextMetadataToDelete)\n",
    "dfDelTextMetadatas = pd.DataFrame(myRQC.getAllResults(), columns=myRQC.getColumnNames())\n",
    "toDelTmdIDs = []\n",
    "if 'tmd_id' in dfDelTextMetadatas.columns:\n",
    "  toDelTmdIDs = pd.unique(sorted(list(dfDelTextMetadatas['tmd_id'])))\n",
    "if len(toDelTmdIDs) > 0:\n",
    "  myRSH.saveDataFrame(dfDelTextMetadatas,\n",
    "                      outdir='output', \n",
    "                      filename=f\"textmetadatas_ready_to_delete{dbname}\",\n",
    "                      extType=outputFormat)\n",
    "  print(f\"Marking for delete textmetadata ids {toDelTmdIDs}\")\n",
    "#  deleteTextMetadatas(toDelTmdIDs)\n",
    "else:\n",
    "  print(\"No textmetadata to process\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Find active editions of active text that have 'to delete' in title or of inactive text\n",
    "'''\n",
    "queryFindEditionToDelete = \\\n",
    "\" SELECT txt_id, txt_owner_id, txt_title, txt_ckn, edn_id, edn_owner_id, edn_description \\\n",
    "  FROM text \\\n",
    "    LEFT JOIN edition ON edn_text_id = txt_id \\\n",
    "  WHERE edn_id IS NOT NULL AND edn_owner_id > 1 AND (edn_description ilike '%delete%' OR txt_owner_id = 1) \\\n",
    "  ORDER BY txt_id, txt_owner_id, edn_owner_id, edn_id;\"\n",
    "myRQC.query(queryFindEditionToDelete)\n",
    "dfDelEditions = pd.DataFrame(myRQC.getAllResults(), columns=myRQC.getColumnNames())\n",
    "toDelEdnIDs = []\n",
    "if 'edn_id' in dfDelEditions.columns:\n",
    "  toDelEdnIDs = pd.unique(sorted(list(dfDelEditions['edn_id'])))\n",
    "if len(toDelEdnIDs) > 0:\n",
    "  myRSH.saveDataFrame(dfDelEditions,\n",
    "                      outdir='output', \n",
    "                      filename=f\"editions_ready_to_delete{dbname}\",\n",
    "                      extType=outputFormat)\n",
    "  print(f\"Marking for delete edition ids {toDelEdnIDs}\")\n",
    "#  deleteEditions(toDelEdnIDs)\n",
    "else:\n",
    "  print(\"No editions to process\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    " find all 'TextPhysical' of 'marked for delete' editions not attached to an active edition\n",
    "'''\n",
    "textPhysSeqTermID = myRQC.getTermIDStrict('textphysical','sequencetype')\n",
    "\n",
    "queryFindTextPhysSequenceToDelete = f\"\\\n",
    "SELECT tp.seq_id as seqid_del, tp.seq_owner_id as del_owner, tp.seq_label as tplabel,\\\n",
    "  d.edn_description, d.edn_id, d.edn_owner_id, d.edn_sequence_ids \\\n",
    "FROM edition a \\\n",
    "  LEFT JOIN edition d ON a.edn_text_id = d.edn_text_id \\\n",
    "  LEFT JOIN sequence tp ON tp.seq_id = ANY(d.edn_sequence_ids) \\\n",
    "WHERE a.edn_id != d.edn_id AND a.edn_owner_id != 1 AND not a.edn_description ilike '%to delete%' \\\n",
    "  AND d.edn_owner_id = 1 \\\n",
    "  AND not tp.seq_id = ANY(a.edn_sequence_ids) AND tp.seq_type_id = {textPhysSeqTermID} \\\n",
    "ORDER BY tp.seq_id;\\\n",
    "\"\n",
    "myRQC.query(queryFindTextPhysSequenceToDelete)\n",
    "dfTextPhysicalSequences = pd.DataFrame(myRQC.getAllResults(), columns=myRQC.getColumnNames())\n",
    "arrToDel = dfTextPhysicalSequences.index[dfTextPhysicalSequences['del_owner'].ne(1)]\n",
    "toDelSeqIDs = []\n",
    "if 'seqid_del' in dfTextPhysicalSequences.columns:\n",
    "  toDelSeqIDs = pd.unique(sorted(list(dfTextPhysicalSequences['seqid_del'].loc[arrToDel])))\n",
    "arrPrevDel = dfTextPhysicalSequences.index[dfTextPhysicalSequences['del_owner'].eq(1)]\n",
    "prevDelSeqIDs = pd.unique(sorted(list(dfTextPhysicalSequences['seqid_del'].loc[arrPrevDel])))\n",
    "print(\"Deleted TP Sequences:\",prevDelSeqIDs)\n",
    "# delete\n",
    "if len(toDelSeqIDs) > 0:\n",
    "  myRSH.saveDataFrame(dfTextPhysicalSequences,\n",
    "                      outdir='output', \n",
    "                      filename=f\"textphysical_sequences_to_delete{dbname}\",\n",
    "                      extType=outputFormat)\n",
    "  print(\"TP Sequences to delete:\",toDelSeqIDs)\n",
    "  print(f\"Marking for delete tp seqids {toDelSeqIDs}\")\n",
    "#  deleteSequences(toDelSeqIDs)\n",
    "else:\n",
    "  print(\"No text physical sequences to process\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    " find all 'Text' sequences of 'marked for delete' editions not attached to an active edition\n",
    "'''\n",
    "textSeqTermID = myRQC.getTermIDStrict('text','sequencetype')\n",
    "\n",
    "queryFindTextSequenceToDelete = f\"\\\n",
    "SELECT tx.seq_id as seqid_del, tx.seq_owner_id as del_owner, tx.seq_label as txlabel,\\\n",
    "  d.edn_description, d.edn_id, d.edn_owner_id, d.edn_sequence_ids \\\n",
    "FROM edition a \\\n",
    "  LEFT JOIN edition d ON a.edn_text_id = d.edn_text_id \\\n",
    "  LEFT JOIN sequence tx ON tx.seq_id = ANY(d.edn_sequence_ids) \\\n",
    "WHERE a.edn_id != d.edn_id AND a.edn_owner_id != 1 AND not a.edn_description ilike '%to delete%' \\\n",
    "  AND d.edn_owner_id = 1 \\\n",
    "  AND not tx.seq_id = ANY(a.edn_sequence_ids) AND tx.seq_type_id = {textSeqTermID} \\\n",
    "ORDER BY tx.seq_id;\\\n",
    "\"\n",
    "myRQC.query(queryFindTextSequenceToDelete)\n",
    "dfTextSequences = pd.DataFrame(myRQC.getAllResults(), columns=myRQC.getColumnNames())\n",
    "arrToDel = dfTextSequences.index[dfTextSequences['del_owner'].ne(1)]\n",
    "toDelSeqIDs = []\n",
    "if 'seqid_del' in dfTextSequences.columns:\n",
    "  toDelSeqIDs = pd.unique(sorted(list(dfTextSequences['seqid_del'].loc[arrToDel])))\n",
    "arrPrevDel = dfTextSequences.index[dfTextSequences['del_owner'].eq(1)]\n",
    "prevDelSeqIDs = pd.unique(sorted(list(dfTextSequences['seqid_del'].loc[arrPrevDel])))\n",
    "print(\"Deleted TX Sequences:\",prevDelSeqIDs)\n",
    "# delete\n",
    "if len(toDelSeqIDs) > 0:\n",
    "  myRSH.saveDataFrame(dfTextSequences,\n",
    "                      outdir='output', \n",
    "                      filename=f\"text_sequences_to_delete{dbname}\",\n",
    "                      extType=outputFormat)\n",
    "  print(\"TX Sequences to delete:\",toDelSeqIDs)\n",
    "  print(f\"Marking {len(toDelSeqIDs)} for delete tx seqids {toDelSeqIDs}\")\n",
    "#  deleteSequences(toDelSeqIDs)\n",
    "else:\n",
    "  print(\"No text sequences to process\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "find all active 'TextDivision' sequences to be delete:\n",
    "  active 'TextDivision' sequences attached to text sequence marked for delete\n",
    "  not attached to an active text sequence of an edition of the same text\n",
    "'''\n",
    "textSeqTermID = myRQC.getTermIDStrict('text','sequencetype')\n",
    "textDivSeqTermID = myRQC.getTermIDStrict('textdivision','text')\n",
    "\n",
    "queryFindTextDivSequenceToDelete = f\"\\\n",
    "SELECT de.edn_id, de.edn_owner_id, de.edn_description as deledn_label, \\\n",
    "  txd.seq_id as txseqid_del, txd.seq_owner_id as txdel_owner, txd.seq_label as txdel_label,\\\n",
    "  tdd.seq_id as tdseqid_del, tdd.seq_owner_id as tddel_owner, tdd.seq_label as tddel_label,\\\n",
    "  txa.seq_id as txseqid_keep, txa.seq_label as tpkeep_label,\\\n",
    "  ae.edn_description as actedn_label \\\n",
    "FROM edition de \\\n",
    "  LEFT JOIN edition ae on ae.edn_text_id = de.edn_text_id \\\n",
    "  LEFT JOIN sequence txd on txd.seq_id = ANY(de.edn_sequence_ids) \\\n",
    "  LEFT JOIN sequence txa on txa.seq_id = ANY(ae.edn_sequence_ids) \\\n",
    "  LEFT JOIN sequence tdd on CONCAT('seq:', tdd.seq_id) = ANY(txd.seq_entity_ids) \\\n",
    "WHERE de.edn_id != ae.edn_id AND de.edn_owner_id = 1 AND ae.edn_owner_id !=1 \\\n",
    "  AND txd.seq_id != txa.seq_id AND txd.seq_type_id = {textSeqTermID} AND txd.seq_owner_id = 1 \\\n",
    "  AND tdd.seq_type_id = {textDivSeqTermID} AND NOT CONCAT('seq:', tdd.seq_id) = ANY(txa.seq_entity_ids) \\\n",
    "  AND txa.seq_type_id = {textSeqTermID} AND txa.seq_owner_id != 1 \\\n",
    "ORDER BY tdd.seq_id; \\\n",
    "\"\n",
    "myRQC.query(queryFindTextDivSequenceToDelete)\n",
    "dfTextDivisionSequences = pd.DataFrame(myRQC.getAllResults(), columns=myRQC.getColumnNames())\n",
    "arrToDel = dfTextDivisionSequences.index[dfTextDivisionSequences['tddel_owner'].ne(1)]\n",
    "arrPrevDel = dfTextDivisionSequences.index[dfTextDivisionSequences['tddel_owner'].eq(1)]\n",
    "toDelSeqIDs = []\n",
    "prevDelSeqIDs = []\n",
    "if 'tdseqid_del' in dfTextDivisionSequences.columns:\n",
    "  toDelSeqIDs = pd.unique(sorted(list(dfTextDivisionSequences['tdseqid_del'].loc[arrToDel])))\n",
    "  prevDelSeqIDs = pd.unique(sorted(list(dfTextDivisionSequences['tdseqid_del'].loc[arrPrevDel])))\n",
    "print(\"TD Sequences to delete:\",toDelSeqIDs)\n",
    "print(\"Deleted TD Sequences:\",prevDelSeqIDs)\n",
    "# delete\n",
    "if len(toDelSeqIDs) > 0:\n",
    "  myRSH.saveDataFrame(dfTextDivisionSequences,\n",
    "                      outdir='output', \n",
    "                      filename=f\"textdivision_sequences_to_delete{dbname}\",\n",
    "                      extType=outputFormat)\n",
    "  print(f\"Marking {len(toDelSeqIDs)} for delete td seqids {toDelSeqIDs}\")\n",
    "#  deleteSequences(toDelSeqIDs)\n",
    "else:\n",
    "  print(\"No text division sequences to process\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "find all active token to be delete:\n",
    "  active token not attached to text division sequence not marked for delete\n",
    "'''\n",
    "textDivSeqTermID = myRQC.getTermIDStrict('textdivision','text')\n",
    "\n",
    "queryFindTextDivSequenceToDelete = f\" \\\n",
    "  SELECT td \\\n",
    "  FROM token \\\n",
    "  WHERE tok_id NOT IN (\\\n",
    "    SELECT DISTINCT(REPLACE(UNNEST(seq_entity_ids),'tok:',''))::int AS tokID \\\n",
    "    FROM sequence \\\n",
    "    WHERE seq_type_id = {textDivSeqTermID} AND seq_owner_id != 1 \\\n",
    "  ) \\\n",
    "  ORDER BY tok_id;\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "  find all active 'LinePhysical' sequences to be delete:\n",
    "  active 'LinePhysical' sequences attached to textphysical sequence marked for delete\n",
    "  not attached to an active textphysical sequence of an edition of the same text\n",
    "'''\n",
    "textPhysSeqTermID = myRQC.getTermIDStrict('textphysical','sequencetype')\n",
    "linePhysSeqTermID = myRQC.getTermIDStrict('linephysical','textphysical')\n",
    "\n",
    "queryFindLinePhysSequenceToDelete = f\"\\\n",
    "SELECT de.edn_id, de.edn_owner_id, de.edn_description as deledn_label, \\\n",
    "  tpd.seq_id as tpseqid_del, tpd.seq_owner_id as tpdel_owner, tpd.seq_label as tpdel_label,\\\n",
    "  lpd.seq_id as lpseqid_del, lpd.seq_owner_id as lpdel_owner, lpd.seq_label as lpdel_label,\\\n",
    "  tpa.seq_id as tpseqid_keep, tpa.seq_label as tpkeep_label,\\\n",
    "  ae.edn_description as actedn_label \\\n",
    "FROM edition de \\\n",
    "  LEFT JOIN edition ae on ae.edn_text_id = de.edn_text_id \\\n",
    "  LEFT JOIN sequence tpd on tpd.seq_id = ANY(de.edn_sequence_ids) \\\n",
    "  LEFT JOIN sequence tpa on tpa.seq_id = ANY(ae.edn_sequence_ids) \\\n",
    "  LEFT JOIN sequence lpd on CONCAT('seq:', lpd.seq_id) = ANY(tpd.seq_entity_ids) \\\n",
    "WHERE de.edn_id != ae.edn_id AND de.edn_owner_id = 1 AND ae.edn_owner_id !=1 \\\n",
    "  AND tpd.seq_id != tpa.seq_id AND tpd.seq_type_id = {textPhysSeqTermID} AND tpd.seq_owner_id = 1 \\\n",
    "  AND lpd.seq_type_id = {linePhysSeqTermID} AND NOT CONCAT('seq:', lpd.seq_id) = ANY(tpa.seq_entity_ids) \\\n",
    "  AND tpa.seq_type_id = {textPhysSeqTermID} AND tpa.seq_owner_id != 1 \\\n",
    "ORDER BY lpd.seq_id; \\\n",
    "\"\n",
    "myRQC.query(queryFindLinePhysSequenceToDelete)\n",
    "dfLinePhysicalSequences = pd.DataFrame(myRQC.getAllResults(), columns=myRQC.getColumnNames())\n",
    "arrToDel = dfLinePhysicalSequences.index[dfLinePhysicalSequences['lpdel_owner'].ne(1)]\n",
    "arrPrevDel = dfLinePhysicalSequences.index[dfLinePhysicalSequences['lpdel_owner'].eq(1)]\n",
    "toDelSeqIDs = []\n",
    "prevDelSeqIDs = []\n",
    "if 'lpseqid_del' in dfLinePhysicalSequences.columns:\n",
    "  toDelSeqIDs = pd.unique(sorted(list(dfLinePhysicalSequences['lpseqid_del'].loc[arrToDel])))\n",
    "  prevDelSeqIDs = pd.unique(sorted(list(dfLinePhysicalSequences['lpseqid_del'].loc[arrPrevDel])))\n",
    "print(\"LP Sequences to delete:\",toDelSeqIDs)\n",
    "print(\"Deleted LP Sequences:\",prevDelSeqIDs)\n",
    "# delete\n",
    "if len(toDelSeqIDs) > 0:\n",
    "  myRSH.saveDataFrame(dfLinePhysicalSequences,\n",
    "                      outdir='output', \n",
    "                      filename=f\"linephysical_sequences_to_delete{dbname}\",\n",
    "                      extType=outputFormat)\n",
    "  print(f\"Marking {len(toDelSeqIDs)} for delete tp seqids {toDelSeqIDs}\")\n",
    "#  deleteSequences(toDelSeqIDs)\n",
    "else:\n",
    "  print(\"No line physical sequences to process\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "Find all to be deleted syllables and ignore any that are in an active Line Physical sequence\n",
    "'''\n",
    "textPhysSeqTermID = myRQC.getTermIDStrict('textphysical','sequencetype')\n",
    "linePhysSeqTermID = myRQC.getTermIDStrict('linephysical','textphysical')\n",
    "\n",
    "# find all syllables from 'marked for delete' LinePhysical sequence that are not makred for delete\n",
    "queryFindLinePhysSyllablesToDelete = f\"\\\n",
    "SELECT  a.lpseqid_del as lpseqid_del, a.sclgid as sclgid, scl_id, scl_owner_id \\\n",
    "FROM (SELECT UNNEST(lpd.seq_entity_ids) as sclgid, lpd.seq_id as lpseqid_del \\\n",
    "      FROM sequence lpd \\\n",
    "      WHERE lpd.seq_owner_id = 1 AND lpd.seq_type_id = {linePhysSeqTermID} \\\n",
    "      ORDER BY sclgid) a \\\n",
    "  LEFT JOIN syllablecluster ON REPLACE(a.sclgid,'scl:','')::int = scl_id \\\n",
    "WHERE scl_owner_id != 1 \\\n",
    "\"\n",
    "toDelSclIDs = []\n",
    "toDelSclGIDs = []\n",
    "cntDelScl = 0\n",
    "myRQC.query(queryFindLinePhysSyllablesToDelete)\n",
    "if myRQC.getResultCount() > 0:\n",
    "  dfSyllablesToDel = pd.DataFrame(myRQC.getAllResults(), columns=myRQC.getColumnNames())\n",
    "  delLPSeqIDs = pd.unique(sorted(list(dfSyllablesToDel['lpseqid_del'])))\n",
    "  toDelSclIDs = pd.unique(sorted(list(dfSyllablesToDel['scl_id'])))\n",
    "  toDelSclGIDs = pd.unique(sorted(list(dfSyllablesToDel['sclgid'])))\n",
    "  cntDelLPSeq = len(delLPSeqIDs)\n",
    "  print(f\"{cntDelLPSeq} line physical deleted:\",delLPSeqIDs)\n",
    "  cntDelScl = len(toDelSclIDs)\n",
    "print(f\"{cntDelScl} syllables to delete:\",toDelSclIDs)\n",
    "\n",
    "\n",
    "if cntDelScl > 0:\n",
    "  '''\n",
    "  Find all active syllables and ignore any that are in marked for delete Line Physical sequence\n",
    "  '''\n",
    "  # find all syllables from active LinePhysical sequences that are not marked for delete\n",
    "  queryFindActiveLinePhysSyllables = f\"\\\n",
    "  SELECT  a.lpseqid_act as lpseqid_act, a.sclgid as sclgid, scl_id, scl_owner_id \\\n",
    "  FROM (SELECT UNNEST(lpa.seq_entity_ids) as sclgid, lpa.seq_id as lpseqid_act \\\n",
    "        FROM sequence lpa \\\n",
    "        WHERE lpa.seq_owner_id != 1 AND lpa.seq_type_id = {linePhysSeqTermID} \\\n",
    "        ORDER BY sclgid) a \\\n",
    "    LEFT JOIN syllablecluster ON REPLACE(a.sclgid,'scl:','')::int = scl_id \\\n",
    "  WHERE scl_owner_id != 1 \\\n",
    "  \"\n",
    "  myRQC.query(queryFindActiveLinePhysSyllables)\n",
    "  if myRQC.getResultCount() > 0:\n",
    "    dfActiveSyllables = pd.DataFrame(myRQC.getAllResults(), columns=myRQC.getColumnNames())\n",
    "    actSclIDs = pd.unique(sorted(list(dfActiveSyllables['scl_id'])))\n",
    "    actSclGIDs = pd.unique(sorted(list(dfActiveSyllables['sclgid'])))\n",
    "    cntActScl = len(actSclIDs)\n",
    "    cntActSclGID = len(actSclGIDs)\n",
    "    print(f\"{cntActScl} active syllables:\",actSclIDs)\n",
    "    print(f\"{cntActSclGID} GIDs of active syllables:\",actSclGIDs)\n",
    "\n",
    "    # check that the del syllables found are not also in active syllable set from \n",
    "    # an active line physical (from cloning)\n",
    "    toKeepSclGIDsOfDels = [ sclGID for sclGID in toDelSclGIDs if sclGID in actSclGIDs]\n",
    "    cntToKeepSclIDs = len(toKeepSclGIDsOfDels)\n",
    "    print(f\"{cntToKeepSclIDs} toDelSclGIDs found to be active syllables:\",toKeepSclGIDsOfDels)\n",
    "    if cntToKeepSclIDs > 0:\n",
    "      #remove active syllables from the to delete syllables\n",
    "      newToDelSclIDs = [sclID for sclID in toDelSclIDs if 'scl:' + str(sclID) not in toKeepSclGIDsOfDels]\n",
    "      if len(newToDelSclIDs) + cntToKeepSclIDs != cntDelScl:\n",
    "        print(f\"WARNING: toDelSclGIDs count {cntDelScl} does not equal new count {len(newToDelSclIDs)} plus active count {cntToKeepSclIDs}\")\n",
    "        print(f\"aborting to mark syllables for delete {toDelSclIDs}\")\n",
    "        cntDelScl = 0\n",
    "      else:\n",
    "        toDelSclIDs = newToDelSclIDs\n",
    "        # delete\n",
    "        cntDelScl = len(toDelSclIDs)\n",
    "  myRSH.saveDataFrame(dfSyllablesToDel,\n",
    "                      outdir='output', \n",
    "                      filename=f\"linephysical_syllables_to_delete{dbname}\",\n",
    "                      extType=outputFormat)\n",
    "  myRSH.saveDataFrame(dfActiveSyllables,\n",
    "                      outdir='output', \n",
    "                      filename=f\"linephysical_syllables_to_keep{dbname}\",\n",
    "                      extType=outputFormat)\n",
    "  print(f\"Marking {cntDelScl} syllables for delete; lp sclids {toDelSclIDs}\")\n",
    "#  if cntDelScl > 0:\n",
    "#    deleteSyllableClusters(toDelSclIDs)\n",
    "else:\n",
    "  print(\"No line physical sequence syllables to process\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "Find and delete all segments attached only to syllables marked for delete\n",
    "'''\n",
    "textPhysSeqTermID = myRQC.getTermIDStrict('textphysical','sequencetype')\n",
    "linePhysSeqTermID = myRQC.getTermIDStrict('linephysical','textphysical')\n",
    "imgBaselineTermID = myRQC.getTermIDStrict('image','baselinetype')\n",
    "tagPaleographyTermID = myRQC.getTermIDStrict('paleography','tagtype')\n",
    "\n",
    "# Find all image segments attached to a syllable marked for delete\n",
    "queryFindSegmentsOfSyllablesToDelete = f\"\\\n",
    "  SELECT seg_id, dsc.scl_id AS scl_del, \\\n",
    "    dsc.scl_owner_id AS del_owner, \\\n",
    "    bln_id, bln_type_id, bln_owner_id, seg_owner_id, seg_image_pos, \\\n",
    "    dsc.scl_grapheme_ids AS grad, dsc.scl_owner_id \\\n",
    "  FROM segment \\\n",
    "  LEFT JOIN syllablecluster dsc ON dsc.scl_segment_id=seg_id \\\n",
    "  LEFT JOIN baseline ON bln_id=ANY(seg_baseline_ids) \\\n",
    "  WHERE dsc.scl_id IS NOT NULL AND dsc.scl_owner_id = 1 \\\n",
    "    AND seg_owner_id !=1 AND seg_image_pos IS NOT NULL \\\n",
    "    AND bln_type_id={imgBaselineTermID} \\\n",
    "  ORDER BY seg_owner_id, seg_id, dsc.scl_id;\\\n",
    "\"\n",
    "delSclSegIDs = []\n",
    "cntDelSclSegs = 0\n",
    "myRQC.query(queryFindSegmentsOfSyllablesToDelete)\n",
    "if myRQC.getResultCount() > 0:\n",
    "  dfDelSclSegments = pd.DataFrame(myRQC.getAllResults(), columns=myRQC.getColumnNames())\n",
    "  delSclSegIDs = pd.unique(sorted(list(dfDelSclSegments['seg_id'])))\n",
    "  myRSH.saveDataFrame(dfDelSclSegments,\n",
    "                      outdir='output', \n",
    "                      filename=f\"del_syllables_image_segments{dbname}\",\n",
    "                      extType=outputFormat)\n",
    "  cntDelSclSegs = len(delSclSegIDs)\n",
    "  print(f\"{cntDelSclSegs} segments attached to deleted encoding clusters:\",delSclSegIDs)\n",
    "\n",
    "\n",
    "if cntDelSclSegs > 0:\n",
    "  '''\n",
    "Find all image segments attached only to a syllable marked for delete\n",
    "  '''\n",
    "  queryFindImageSegmentsToDelete = f\"\\\n",
    "    SELECT seg_id, dsc.scl_id AS scl_del, sca.scl_id AS scl_act,\\\n",
    "        dsc.scl_owner_id AS del_owner, sca.scl_owner_id AS act_owner,\\\n",
    "        bln_id, bln_type_id, bln_owner_id, seg_image_pos,\\\n",
    "        dsc.scl_grapheme_ids AS grad, dsc.scl_owner_id,\\\n",
    "        sca.scl_owner_id, sca.scl_grapheme_ids AS graa \\\n",
    "    FROM segment \\\n",
    "    LEFT JOIN syllablecluster dsc ON dsc.scl_segment_id=seg_id \\\n",
    "    LEFT JOIN baseline ON bln_id=ANY(seg_baseline_ids) \\\n",
    "    LEFT JOIN syllablecluster sca ON sca.scl_segment_id=seg_id \\\n",
    "    LEFT JOIN sequence on CONCAT('seq:', sca.scl_id) = ANY(seq_entity_ids) \\\n",
    "    WHERE dsc.scl_id is not NULL AND dsc.scl_owner_id = 1 AND dsc.scl_id != sca.scl_id AND sca.scl_owner_id != 1 \\\n",
    "      AND seg_owner_id !=1 AND seg_image_pos is not NULL AND seq_owner_id = 1 AND seq_type_id = {linePhysSeqTermID} \\\n",
    "      AND bln_type_id={imgBaselineTermID} \\\n",
    "    ORDER BY seg_id, dsc.scl_id;\\\n",
    "  \"\n",
    "  myRQC.query(queryFindImageSegmentsToDelete)\n",
    "  if myRQC.getResultCount() > 0:\n",
    "    dfDelImageSegments = pd.DataFrame(myRQC.getAllResults(), columns=myRQC.getColumnNames())\n",
    "    toDelSegIDs = pd.unique(sorted(list(dfDelImageSegments['seg_id'])))\n",
    "    cntDelSegs = len(toDelSegIDs)\n",
    "    print(f\"{cntDelSegs} toDelSegIDs segments to delete:\",toDelSegIDs)\n",
    "    myRSH.saveDataFrame(dfDelImageSegments,\n",
    "                        outdir='output', \n",
    "                        filename=f\"del_syllable_segments_to_delete{dbname}\",\n",
    "                        extType=outputFormat)\n",
    "    print(f\"Marking {cntDelSegs} syllables for delete; lp sclids {toDelSegIDs}\")\n",
    "#    deleteSegments(toDelSegIDs)\n",
    "  else:\n",
    "    print(\"No image segments to delete found\")\n",
    "else:\n",
    "  print(\"No image segments to process\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "Find all syllableclusters that are 'marked for delete' that are tagged\n",
    "'''\n",
    "tagPaleographyTermID = myRQC.getTermIDStrict('paleography','tagtype')\n",
    "\n",
    "# Find all annotation with links to a syllable marked for delete\n",
    "queryFindAnnotationsWithSyllablesToRemove = f\"\\\n",
    "  SELECT ano_id, ano_type_id as tagID, ano_linkto_ids as links, \\\n",
    "         ARRAY_AGG(CONCAT('scl:',a.scl_id)) AS sclLinksToRemove \\\n",
    "  FROM annotation \\\n",
    "    LEFT JOIN \\\n",
    "      (SELECT scl_id \\\n",
    "      FROM syllablecluster \\\n",
    "      WHERE scl_owner_id = 1 \\\n",
    "        AND scl_id IN \\\n",
    "        (SELECT  DISTINCT(REPLACE(UNNEST(ano_linkto_ids),'scl:',''))::int as scl_id \\\n",
    "         FROM annotation \\\n",
    "         WHERE ano_owner_id != 1 \\\n",
    "           AND ano_type_id IN (SELECT trm_id \\\n",
    "                               FROM term \\\n",
    "                               WHERE trm_parent_id in (SELECT trm_id \\\n",
    "                                                       FROM term \\\n",
    "                                                       WHERE trm_parent_id = {tagPaleographyTermID}))\\\n",
    "           AND ano_linkto_ids[1] LIKE 'scl%' \\\n",
    "         ORDER BY scl_id) \\\n",
    "      ORDER BY scl_id) a ON CONCAT('scl:',a.scl_id) = ANY(ano_linkto_ids) \\\n",
    "  WHERE a.scl_id IS NOT null \\\n",
    "  GROUP BY ano_id; \\\n",
    "\"\n",
    "myRQC.query(queryFindAnnotationsWithSyllablesToRemove)\n",
    "if myRQC.getResultCount() > 0:\n",
    "  dfAnoWithDelScls = pd.DataFrame(myRQC.getAllResults(), columns=myRQC.getColumnNames())\n",
    "  myRSH.saveDataFrame(dfAnoWithDelScls,\n",
    "                      outdir='output', \n",
    "                      filename=f\"anoTags_linked_with_del_syllables{dbname}\",\n",
    "                      extType=outputFormat)\n",
    "  anoInfoWithDelScls = myRQC.getRowsAsIndexMultiDict(columnName = 'ano_id')\n",
    "  for anoID in anoInfoWithDelScls.keys():\n",
    "    anoInfo = anoInfoWithDelScls[anoID][0]\n",
    "    tag = myRQC.getTermCode(anoInfo['tagid'])\n",
    "    links = anoInfo['links']\n",
    "    sclLinksToRemove = anoInfo['scllinkstoremove']\n",
    "    print(f\" tag {tag} in ano {anoID} has {len(links)} links with {len(sclLinksToRemove)} to be removed\")\n",
    "    for sclGID in sclLinksToRemove:\n",
    "      links.remove(sclGID)\n",
    "    print(f\"tag {tag} now has {len(links)} links for updating anoID {anoID}\")\n",
    "#    myRQC.update(\"annotation\",{\"ano_linkto_ids\":\"{\"+','.join([str(i) for i in links])+\"}\"},{\"ano_id\":anoID})\n",
    "#    if myRQC.hasError():\n",
    "#      print(f\"Error while updating anoID {anoID} - {myRQC.getError()}\")\n",
    "#    else:\n",
    "#      print(f\"Update of tag {tag} (ano:{anoID}) was successful\")\n",
    "else:\n",
    "  print(\"No sclIDs linked to annoTag to be removed\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myRQC.query(\n",
    "  '''\n",
    "   WITH allLinkedTextDivSeqIDs AS (-- list all TD sequences in an active text sequence\n",
    "    SELECT replace(unnest(seq_entity_ids),'seq:','')::int as seqID\n",
    "    FROM sequence\n",
    "    WHERE seq_type_id = 738 AND seq_owner_id != 1\n",
    "   ),\n",
    "   activeTextDivIDs AS (-- seq ids of active text division sequence linked to text sequence\n",
    "    SELECT seq_id\n",
    "    FROM sequence\n",
    "    WHERE seq_owner_id != 1\n",
    "     AND seq_id IN (SELECT seqID FROM allLinkedTextDivSeqIDs)\n",
    "    ORDER BY seq_id\n",
    "   ),\n",
    "   orphTextDivIDs AS (-- seq ids of text division sequence not linked to an active text sequence\n",
    "    SELECT seq_id\n",
    "    FROM sequence\n",
    "    WHERE seq_type_id = 739 AND seq_owner_id != 1\n",
    "     AND NOT seq_id IN (SELECT seqID FROM allLinkedTextDivSeqIDs)\n",
    "   ),\n",
    "   orphWordGIDs AS (\n",
    "    SELECT seq_id AS tdseq_id, UNNEST(seq_entity_ids) AS orph_gid\n",
    "    FROM sequence\n",
    "    WHERE seq_id IN (SELECT seq_id FROM orphTextDivIDs)\n",
    "   ),\n",
    "   wordGIDs AS (\n",
    "    SELECT seq_id AS tdseq_id, UNNEST(seq_entity_ids) AS word_gid\n",
    "    FROM sequence\n",
    "    WHERE seq_id IN ( SELECT seq_id FROM activeTextDivIDs)\n",
    "   ),\n",
    "   orphTokGIDs AS (\n",
    "    SELECT *\n",
    "    FROM orphWordGIDs\n",
    "    WHERE orph_gid LIKE 'tok:%'\n",
    "    ORDER BY tdseq_id, orph_gid\n",
    "   ),\n",
    "   orphTok_n_IDs AS (\n",
    "    SELECT 'tok' AS prefix, REPLACE(orph_gid, 'tok:', '')::int AS entid\n",
    "    FROM orphTokGIDs\n",
    "   ),\n",
    "   orphTokIDs AS (\n",
    "    SELECT DISTINCT(entid) AS tok_id\n",
    "    FROM orphTok_n_IDs\n",
    "    ORDER BY entid\n",
    "   ),\n",
    "   orphCmpGIDs AS (\n",
    "    SELECT *\n",
    "    FROM orphWordGIDs\n",
    "    WHERE orph_gid like 'cmp:%'\n",
    "    ORDER BY orph_gid\n",
    "   ),\n",
    "   orphCmp_n_IDs AS (\n",
    "    SELECT 'cmp' AS prefix, REPLACE(orph_gid, 'cmp:', '')::int AS entid\n",
    "    FROM orphCmpGIDs\n",
    "   ),\n",
    "   orphCmpIDs AS (\n",
    "    SELECT DISTINCT(entid) AS cmp_id\n",
    "    FROM orphCmp_n_IDs\n",
    "    ORDER BY entid\n",
    "   ),\n",
    "   orphPrefixEntIDs AS ( -- all word prefix, id in orphaned text divisions\n",
    "    SELECT * \n",
    "    FROM (\n",
    "     SELECT * FROM orphCmp_n_IDs\n",
    "     UNION\n",
    "     SELECT * FROM orphTok_n_IDs\n",
    "     ) a\n",
    "    ORDER BY a.prefix, a.entid\n",
    "   ),\n",
    "   misNeedCleanSeqIDs AS ( --find all sequence containing orphaned words needing to be cleaned\n",
    "    SELECT DISTINCT(seq_id), ARRAY_AGG(orph_gid)::text removeGIDs\n",
    "    FROM sequence\n",
    "     LEFT JOIN orphWordGIDs ON orph_gid = ANY(seq_entity_ids)\n",
    "    WHERE seq_type_id != 739 AND tdseq_id IS NOT null\n",
    "    GROUP BY seq_id\n",
    "    ORDER BY seq_id\n",
    "   ),\n",
    "   adoptedWordGIDs AS ( --find all ent gids in another text division\n",
    "    SELECT seq_id, tdseq_id, orph_gid\n",
    "    FROM sequence\n",
    "     LEFT JOIN orphWordGIDs ON orph_gid = ANY(seq_entity_ids)\n",
    "    WHERE seq_type_id = 739 AND tdseq_id IS NOT null\n",
    "     AND seq_id IN (SELECT seq_id FROM activeTextDivIDs)\n",
    "    ORDER BY tdseq_id, orph_gid\n",
    "   ),\n",
    "   cmpContainedOrphGIDs as ( --find all compounds containing orphaned word GIDs\n",
    "    SELECT cmp_id, orph_gid\n",
    "    FROM compound\n",
    "     LEFT JOIN orphWordGIDs ON orph_gid = ANY(cmp_component_ids)\n",
    "    WHERE orph_gid IS NOT null\n",
    "    ORDER BY cmp_id, orph_gid\n",
    "   )\n",
    "\n",
    "   SELECT a.prop,a.val \n",
    "   FROM (\n",
    "     SELECT 'activeTDCount' AS prop, COUNT(seq_id)::text AS val FROM activeTextDivIDs\n",
    "     UNION\n",
    "     SELECT 'activeTDSeqIDs' AS prop, ARRAY_AGG(seq_id)::text AS val FROM activeTextDivIDs\n",
    "     UNION\n",
    "     SELECT 'orphTDCount' AS prop, COUNT(seq_id)::text AS val FROM orphTextDivIDs\n",
    "     UNION\n",
    "     SELECT 'orphTDSeqIDs' AS prop, ARRAY_AGG(seq_id)::text AS val FROM orphTextDivIDs\n",
    "     UNION\n",
    "     SELECT 'orphWordCount' AS prop, COUNT(DISTINCT(orph_gid))::text AS val FROM orphWordGIDs\n",
    "     UNION\n",
    "     SELECT 'orphWordGIDs' AS prop, ARRAY_AGG(DISTINCT(orph_gid))::text AS val FROM orphWordGIDs\n",
    "     UNION\n",
    "     SELECT 'adoptedWordCount' AS prop, COUNT(orph_gid)::text AS val FROM adoptedWordGIDs\n",
    "     UNION\n",
    "     SELECT 'adoptedWordGIDs' AS prop, ARRAY_AGG(orph_gid)::text AS val FROM adoptedWordGIDs\n",
    "     UNION\n",
    "     SELECT 'cmpContainedWordCount' AS prop, COUNT(orph_gid)::text AS val FROM cmpContainedOrphGIDs\n",
    "     UNION\n",
    "     SELECT 'cmpContainedWordGIDs' AS prop, ARRAY_AGG(orph_gid)::text AS val FROM cmpContainedOrphGIDs\n",
    "     UNION\n",
    "     SELECT 'orphTokCount' AS prop, COUNT(tok_id)::text AS val FROM orphTokIDs\n",
    "     UNION\n",
    "     SELECT 'orphTokIDs' AS prop, ARRAY_AGG(tok_id)::text AS val FROM orphTokIDs\n",
    "     UNION\n",
    "     SELECT 'orphCmpCount' AS prop, COUNT(cmp_id)::text AS val FROM orphCmpIDs\n",
    "     UNION\n",
    "     SELECT 'orphCmpIDs' AS prop, ARRAY_AGG(cmp_id)::text AS val FROM orphCmpIDs\n",
    "     UNION\n",
    "     SELECT CONCAT('removeFromSeq:',seq_id) AS prop, removeGIDs AS val FROM misNeedCleanSeqIDs\n",
    "      ) a\n",
    "   ORDER BY a.prop\n",
    "  '''\n",
    "  )\n",
    "if myRQC.getResultCount() > 0:\n",
    "  dfTextDivWordCleanupInfo = pd.DataFrame(myRQC.getAllResults(), columns=myRQC.getColumnNames())\n",
    "  myRSH.saveDataFrame(dfTextDivWordCleanupInfo,\n",
    "                      outdir='output', \n",
    "                      filename=f\"Text Div and Word Cleanup Info {dbname}\",\n",
    "                      extType=outputFormat)\n",
    "  dictInfo = myRQC.getRowsAsKVDict(kColIndex = 0, vColIndex =1)\n",
    "  gidStillActiveWords = None\n",
    "  cntStillActiveWords = int(dictInfo['adoptedWordCount'])\n",
    "  if cntStillActiveWords > 0:\n",
    "    gidStillActiveWords = dictInfo['adoptedWordGIDs'].strip('{').strip('}').split(',').sort()\n",
    "  gidContainedActiveWords = None\n",
    "  cntContainedActiveWords = int(dictInfo['cmpContainedWordCount'])\n",
    "  if cntContainedActiveWords > 0:\n",
    "    gidContainedActiveWords = dictInfo['cmpContainedWordGIDs'].strip('{').strip('}').split(',').sort()\n",
    "  orphTDSeqIDs = None\n",
    "  cntOrphTDSeqIDs = int(dictInfo['orphTDCount'])\n",
    "  if cntOrphTDSeqIDs > 0:\n",
    "    orphTDSeqIDs = [int(x) for x in dictInfo['orphTDSeqIDs'].strip('{').strip('}').split(',')]\n",
    "#    deleteSequences(orphTDSeqIDs)\n",
    "  orphTokIDs = None\n",
    "  cntOrphTokIDs = int(dictInfo['orphTokCount'])\n",
    "  if cntOrphTokIDs > 0:\n",
    "    orphTokIDs = [int(x) for x in dictInfo['orphTokIDs'].strip('{').strip('}').split(',')]\n",
    "#    deleteTokens(orphTokIDs)\n",
    "  orphCmpIDs = None\n",
    "  cntOrphCmpIDs = int(dictInfo['orphCmpCount'])\n",
    "  if cntOrphCmpIDs > 0:\n",
    "    orphCmpIDs = [int(x) for x in dictInfo['orphCmpIDs'].strip('{').strip('}').split(',')]\n",
    "  if str(dictInfo.keys()).find('removeFromSeq') > -1:\n",
    "    cleanUpSeqCmdList = [['seq:'+key[14:],'remove',dictInfo[key].strip('{').strip('}').split(',')] for key in dictInfo.keys() if key.startswith('removeFromSeq')]\n",
    "    adjustlist = [['all',dbname,cleanUpSeqCmdList]]\n",
    "#    rlm.adjustChildLinks(adjustlist,myRQC)\n",
    "\n",
    "elif myRQC.hasError():\n",
    "  print(f\"Fail to obtain orphan info {myRQC.getError()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rlm.adjustChildLinks(adjustlist,myRQC)\n",
    "#deleteSequences(orphTDSeqIDs)\n",
    "#orphTDSeqIDs\n",
    "#deleteTokens(orphTokIDs)\n",
    "#orphTokIDs\n",
    "#adjustlist"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e4cce46d6be9934fbd27f9ca0432556941ea5bdf741d4f4d64c6cd7f8dfa8fba"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
