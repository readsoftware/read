{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#add parent dir to module search path to find readQueryCursor module\n",
    "sys.path.insert(0,os.path.dirname(os.getcwd()))\n",
    "#print(sys.path)\n",
    "import module.readQueryCursor as rqc\n",
    "import module.readStatistics as rsh\n",
    "\n",
    "dbname = 'testdb'\n",
    "\n",
    "conf = rqc.readConnConfig.copy()\n",
    "conf['database'] = dbname\n",
    "conf['user'] = os.getenv('POSTGRES_USER')\n",
    "conf['password'] = os.getenv('POSTGRES_PASSWORD')\n",
    "myRQC = rqc.ReadQueryCursor(conf)\n",
    "\n",
    "# set default connection for ReadStatsHelper\n",
    "rsh.setReadStatsConnParameter(key='database', value=dbname)\n",
    "rsh.setReadStatsConnParameter(key='user', value=conf['user'])\n",
    "rsh.setReadStatsConnParameter(key='password', value=conf['password'])\n",
    "myRSH = rsh.ReadStatisticsHelper(myRQC)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deleteEntities(tableName = None, prefix = None, entIDs = None):\n",
    "  '''\n",
    "  Mark for delete all entities tableName table with an prefix_id in entIDs\n",
    "  '''\n",
    "  if not isinstance(entIDs, np.ndarray) or len(entIDs) == 0 or tableName == None or prefix == None:\n",
    "    print(f\"aborting delete of {tableName} with ids {entIDs}\")\n",
    "    return None\n",
    "  entCnt = len(entIDs)\n",
    "#  queryMarkEtitiesForDelete = f\" UPDATE {tableName} SET {prefix}_owner_id = 1, {prefix}_visibility_ids = '{{5}}' \" + \\\n",
    "#                              f\" WHERE {prefix}_id in ({','.join([str(id) for id in entIDs])}); \"\n",
    "#  print(f\"update query = {queryMarkEtitiesForDelete}\")\n",
    "  owneridColLabel = prefix + \"_owner_id\"\n",
    "  visIDsColLabel = prefix + \"_visibility_ids\"\n",
    "  pkColLabel = prefix + \"_id\"\n",
    "  updCnt = 0\n",
    "  for id in entIDs:\n",
    "    myRQC.update(tableName,{owneridColLabel:\"1\",visIDsColLabel : \"{\" + \"5}\"},{pkColLabel:str(id)})\n",
    "    #print(\"update query = \",myRQC.getQuery())\n",
    "#  myRQC.query(queryMarkEtitiesForDelete)\n",
    "    if myRQC.getError():\n",
    "      print(f\"query to mark {tableName} entity id({id}) for delete failed\", myRQC.getError())\n",
    "      return myRQC.getError()\n",
    "    else:\n",
    "      updCnt += 1\n",
    "  if updCnt != entCnt:\n",
    "    return f\"result count {updCnt} did not equal count requested {entCnt}\"\n",
    "  return f\"Success: {entCnt} {tableName}s marked for delete\"\n",
    "\n",
    "\n",
    "def deleteTexts(txtIDs = None):\n",
    "  return deleteEntities('text','txt',txtIDs)\n",
    "\n",
    "def deleteText(txtID):\n",
    "  return deleteTexts([txtID])\n",
    "\n",
    "\n",
    "def deleteEditions(ednIDs = None):\n",
    "  return deleteEntities('edition','edn',ednIDs)\n",
    "\n",
    "def deleteEdition(ednID):\n",
    "  return deleteEditions([ednID])\n",
    "\n",
    "\n",
    "def deleteSequences(seqIDs = None):\n",
    "  return deleteEntities('sequence','seq',seqIDs)\n",
    "\n",
    "def deleteSequence(seqID):\n",
    "  return deleteSequences([seqID])\n",
    "\n",
    "\n",
    "def deleteSyllableClusters(sclIDs = None):\n",
    "  return deleteEntities('syllablecluster','scl',sclIDs)\n",
    "\n",
    "def deleteSyllableCluster(sclID):\n",
    "  return deleteSyllableClusters([sclID])\n",
    "\n",
    "\n",
    "def deleteSegments(segIDs = None):\n",
    "  return deleteEntities('segment','seg',segIDs)\n",
    "\n",
    "def deleteSegment(segID):\n",
    "  return deleteSegments([segID])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Find active texts that have 'to delete' in title or invNo or no title\n",
    "'''\n",
    "queryFindTextToDelete = \\\n",
    "\" SELECT txt_id, txt_owner_id, edn_owner_id, txt_title, txt_ckn, edn_id, edn_description \\\n",
    "  FROM text \\\n",
    "    LEFT JOIN edition ON edn_text_id = txt_id \\\n",
    "  WHERE txt_owner_id > 1 \\\n",
    "    AND (txt_title ilike '%delete%' OR txt_ckn ilike '%delete%' OR txt_title IS NULL) \\\n",
    "  ORDER BY txt_owner_id,txt_id;\"\n",
    "myRQC.query(queryFindTextToDelete)\n",
    "dfDelTexts = pd.DataFrame(myRQC.getAllResults(), columns=myRQC.getColumnNames())\n",
    "toDelTxtIDs = []\n",
    "if 'txt_id' in dfDelTexts.columns:\n",
    "  toDelTxtIDs = pd.unique(sorted(list(dfDelTexts['txt_id'])))\n",
    "if len(toDelTxtIDs) > 0:\n",
    "  myRSH.saveDataFrame(dfDelTexts,\n",
    "                      outdir='output', \n",
    "                      filename=f\"texts_ready_to_delete{dbname}\",\n",
    "                      extType=\"csv\")\n",
    "  print(f\"Marking for delete text ids {toDelTxtIDs}\")\n",
    "#  deleteTexts(toDelTxtIDs)\n",
    "else:\n",
    "  print(\"No texts to process\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Find active editions of active text that have 'to delete' in title or of inactive text\n",
    "'''\n",
    "queryFindEditionToDelete = \\\n",
    "\" SELECT txt_id, txt_owner_id, txt_title, txt_ckn, edn_id, edn_owner_id, edn_description \\\n",
    "  FROM text \\\n",
    "    LEFT JOIN edition ON edn_text_id = txt_id \\\n",
    "  WHERE edn_id IS NOT NULL AND edn_owner_id > 1 AND (edn_description ilike '%delete%' OR txt_owner_id = 1) \\\n",
    "  ORDER BY txt_id, txt_owner_id, edn_owner_id, edn_id;\"\n",
    "myRQC.query(queryFindEditionToDelete)\n",
    "dfDelEditions = pd.DataFrame(myRQC.getAllResults(), columns=myRQC.getColumnNames())\n",
    "toDelEdnIDs = []\n",
    "if 'edn_id' in dfDelEditions.columns:\n",
    "  toDelEdnIDs = pd.unique(sorted(list(dfDelEditions['edn_id'])))\n",
    "if len(toDelEdnIDs) > 0:\n",
    "  myRSH.saveDataFrame(dfDelEditions,\n",
    "                      outdir='output', \n",
    "                      filename=f\"editions_ready_to_delete{dbname}\",\n",
    "                      extType=\"csv\")\n",
    "  print(f\"Marking for delete edition ids {toDelEdnIDs}\")\n",
    "#  deleteEditions(toDelEdnIDs)\n",
    "else:\n",
    "  print(\"No editions to process\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    " find all 'TextPhysical' of 'marked for delete' editions not attached to an active edition\n",
    "'''\n",
    "textPhysSeqTermID = myRQC.getTermIDStrict('textphysical','sequencetype')\n",
    "\n",
    "queryFindTextPhysSequenceToDelete = f\"\\\n",
    "SELECT tp.seq_id as seqid_del, tp.seq_owner_id as del_owner, tp.seq_label as tplabel,\\\n",
    "  d.edn_description, d.edn_id, d.edn_owner_id, d.edn_sequence_ids \\\n",
    "FROM edition a \\\n",
    "  LEFT JOIN edition d ON a.edn_text_id = d.edn_text_id \\\n",
    "  LEFT JOIN sequence tp ON tp.seq_id = ANY(d.edn_sequence_ids) \\\n",
    "WHERE a.edn_id != d.edn_id AND a.edn_owner_id != 1 AND not a.edn_description ilike '%to delete%' \\\n",
    "  AND d.edn_owner_id = 1 \\\n",
    "  AND not tp.seq_id = ANY(a.edn_sequence_ids) AND tp.seq_type_id = {textPhysSeqTermID} \\\n",
    "ORDER BY tp.seq_id;\\\n",
    "\"\n",
    "myRQC.query(queryFindTextPhysSequenceToDelete)\n",
    "dfTextPhysicalSequences = pd.DataFrame(myRQC.getAllResults(), columns=myRQC.getColumnNames())\n",
    "arrToDel = dfTextPhysicalSequences.index[dfTextPhysicalSequences['del_owner'].ne(1)]\n",
    "toDelSeqIDs = []\n",
    "if 'seqid_del' in dfTextPhysicalSequences.columns:\n",
    "  toDelSeqIDs = pd.unique(sorted(list(dfTextPhysicalSequences['seqid_del'].loc[arrToDel])))\n",
    "arrPrevDel = dfTextPhysicalSequences.index[dfTextPhysicalSequences['del_owner'].eq(1)]\n",
    "prevDelSeqIDs = pd.unique(sorted(list(dfTextPhysicalSequences['seqid_del'].loc[arrPrevDel])))\n",
    "print(\"Deleted TP Sequences:\",prevDelSeqIDs)\n",
    "# delete\n",
    "if len(toDelSeqIDs) > 0:\n",
    "  myRSH.saveDataFrame(dfTextPhysicalSequences,\n",
    "                      outdir='output', \n",
    "                      filename=f\"textphysical_sequences_to_delete{dbname}\",\n",
    "                      extType=\"csv\")\n",
    "  print(\"TP Sequences to delete:\",toDelSeqIDs)\n",
    "  print(f\"Marking for delete tp seqids {toDelSeqIDs}\")\n",
    "#  deleteSequences(toDelSeqIDs)\n",
    "else:\n",
    "  print(\"No text physical sequences to process\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "find all active 'LinePhysical' sequences to be delete:\n",
    "  active 'LinePhysical' sequences attached to textphysical sequence marked for delete\n",
    "  not attached to an active textphysical sequence of an edition of the same text\n",
    "'''\n",
    "textPhysSeqTermID = myRQC.getTermIDStrict('textphysical','sequencetype')\n",
    "linePhysSeqTermID = myRQC.getTermIDStrict('linephysical','textphysical')\n",
    "\n",
    "queryFindLinePhysSequenceToDelete = f\"\\\n",
    "SELECT de.edn_id, de.edn_owner_id, de.edn_description as deledn_label, \\\n",
    "  tpd.seq_id as tpseqid_del, tpd.seq_owner_id as tpdel_owner, tpd.seq_label as tpdel_label,\\\n",
    "  lpd.seq_id as lpseqid_del, lpd.seq_owner_id as lpdel_owner, lpd.seq_label as lpdel_label,\\\n",
    "  tpa.seq_id as tpseqid_keep, tpa.seq_label as tpkeep_label,\\\n",
    "  ae.edn_description as actedn_label \\\n",
    "FROM edition de \\\n",
    "  LEFT JOIN edition ae on ae.edn_text_id = de.edn_text_id \\\n",
    "  LEFT JOIN sequence tpd on tpd.seq_id = ANY(de.edn_sequence_ids) \\\n",
    "  LEFT JOIN sequence tpa on tpa.seq_id = ANY(ae.edn_sequence_ids) \\\n",
    "  LEFT JOIN sequence lpd on CONCAT('seq:', lpd.seq_id) = ANY(tpd.seq_entity_ids) \\\n",
    "WHERE de.edn_id != ae.edn_id AND de.edn_owner_id = 1 AND ae.edn_owner_id !=1 \\\n",
    "  AND tpd.seq_id != tpa.seq_id AND tpd.seq_type_id = {textPhysSeqTermID} AND tpd.seq_owner_id = 1 \\\n",
    "  AND lpd.seq_type_id = {linePhysSeqTermID} AND NOT CONCAT('seq:', lpd.seq_id) = ANY(tpa.seq_entity_ids) \\\n",
    "  AND tpa.seq_type_id = {textPhysSeqTermID} AND tpa.seq_owner_id != 1 \\\n",
    "ORDER BY lpd.seq_id; \\\n",
    "\"\n",
    "myRQC.query(queryFindLinePhysSequenceToDelete)\n",
    "dfLinePhysicalSequences = pd.DataFrame(myRQC.getAllResults(), columns=myRQC.getColumnNames())\n",
    "arrToDel = dfLinePhysicalSequences.index[dfLinePhysicalSequences['lpdel_owner'].ne(1)]\n",
    "arrPrevDel = dfLinePhysicalSequences.index[dfLinePhysicalSequences['lpdel_owner'].eq(1)]\n",
    "toDelSeqIDs = []\n",
    "prevDelSeqIDs = []\n",
    "if 'lpseqid_del' in dfLinePhysicalSequences.columns:\n",
    "  toDelSeqIDs = pd.unique(sorted(list(dfLinePhysicalSequences['lpseqid_del'].loc[arrToDel])))\n",
    "  prevDelSeqIDs = pd.unique(sorted(list(dfLinePhysicalSequences['lpseqid_del'].loc[arrPrevDel])))\n",
    "print(\"LP Sequences to delete:\",toDelSeqIDs)\n",
    "print(\"Deleted LP Sequences:\",prevDelSeqIDs)\n",
    "# delete\n",
    "if len(toDelSeqIDs) > 0:\n",
    "  myRSH.saveDataFrame(dfLinePhysicalSequences,\n",
    "                      outdir='output', \n",
    "                      filename=f\"linephysical_sequences_to_delete{dbname}\",\n",
    "                      extType=\"csv\")\n",
    "  print(f\"Marking for delete tp seqids {toDelSeqIDs}\")\n",
    "#  deleteSequences(toDelSeqIDs)\n",
    "else:\n",
    "  print(\"No line physical sequences to process\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "Find all to be deleted syllables and ignore any that are in an active Line Physical sequence\n",
    "'''\n",
    "textPhysSeqTermID = myRQC.getTermIDStrict('textphysical','sequencetype')\n",
    "linePhysSeqTermID = myRQC.getTermIDStrict('linephysical','textphysical')\n",
    "\n",
    "# find all syllables from 'marked for delete' LinePhysical sequence that are not makred for delete\n",
    "queryFindLinePhysSyllablesToDelete = f\"\\\n",
    "SELECT  a.lpseqid_del as lpseqid_del, a.sclgid as sclgid, scl_id, scl_owner_id \\\n",
    "FROM (SELECT UNNEST(lpd.seq_entity_ids) as sclgid, lpd.seq_id as lpseqid_del \\\n",
    "      FROM sequence lpd \\\n",
    "      WHERE lpd.seq_owner_id = 1 AND lpd.seq_type_id = {linePhysSeqTermID} \\\n",
    "      ORDER BY sclgid) a \\\n",
    "  LEFT JOIN syllablecluster ON REPLACE(a.sclgid,'scl:','')::int = scl_id \\\n",
    "WHERE scl_owner_id != 1 \\\n",
    "\"\n",
    "toDelSclIDs = []\n",
    "toDelSclGIDs = []\n",
    "cntDelScl = 0\n",
    "myRQC.query(queryFindLinePhysSyllablesToDelete)\n",
    "if myRQC.getResultCount() > 0:\n",
    "  dfSyllablesToDel = pd.DataFrame(myRQC.getAllResults(), columns=myRQC.getColumnNames())\n",
    "  delLPSeqIDs = pd.unique(sorted(list(dfSyllablesToDel['lpseqid_del'])))\n",
    "  toDelSclIDs = pd.unique(sorted(list(dfSyllablesToDel['scl_id'])))\n",
    "  toDelSclGIDs = pd.unique(sorted(list(dfSyllablesToDel['sclgid'])))\n",
    "  cntDelLPSeq = len(delLPSeqIDs)\n",
    "  print(f\"{cntDelLPSeq} line physical deleted:\",delLPSeqIDs)\n",
    "  cntDelScl = len(toDelSclIDs)\n",
    "  print(f\"{cntDelScl} syllables to delete:\",toDelSclGIDs)\n",
    "print(f\"{cntDelScl} syllables to delete:\",toDelSclIDs)\n",
    "\n",
    "\n",
    "if cntDelScl > 0:\n",
    "  '''\n",
    "  Find all active syllables and ignore any that are in marked for delete Line Physical sequence\n",
    "  '''\n",
    "  # find all syllables from active LinePhysical sequences that are not marked for delete\n",
    "  queryFindActiveLinePhysSyllables = f\"\\\n",
    "  SELECT  a.lpseqid_act as lpseqid_act, a.sclgid as sclgid, scl_id, scl_owner_id \\\n",
    "  FROM (SELECT UNNEST(lpa.seq_entity_ids) as sclgid, lpa.seq_id as lpseqid_act \\\n",
    "        FROM sequence lpa \\\n",
    "        WHERE lpa.seq_owner_id != 1 AND lpa.seq_type_id = {linePhysSeqTermID} \\\n",
    "        ORDER BY sclgid) a \\\n",
    "    LEFT JOIN syllablecluster ON REPLACE(a.sclgid,'scl:','')::int = scl_id \\\n",
    "  WHERE scl_owner_id != 1 \\\n",
    "  \"\n",
    "  myRQC.query(queryFindActiveLinePhysSyllables)\n",
    "  if myRQC.getResultCount() > 0:\n",
    "    dfActiveSyllables = pd.DataFrame(myRQC.getAllResults(), columns=myRQC.getColumnNames())\n",
    "    actSclIDs = pd.unique(sorted(list(dfActiveSyllables['scl_id'])))\n",
    "    actSclGIDs = pd.unique(sorted(list(dfActiveSyllables['sclgid'])))\n",
    "    cntActScl = len(actSclIDs)\n",
    "    cntActSclGID = len(actSclGIDs)\n",
    "    print(f\"{cntActScl} active syllables:\",actSclIDs)\n",
    "    print(f\"{cntActSclGID} GIDs of active syllables:\",actSclGIDs)\n",
    "\n",
    "    # check that the del syllables found are not also in active syllable set from \n",
    "    # an active line physical (from cloning)\n",
    "    toKeepSclGIDsOfDels = [ sclGID for sclGID in toDelSclGIDs if sclGID in actSclGIDs]\n",
    "    cntToKeepSclIDs = len(toKeepSclGIDsOfDels)\n",
    "    print(f\"{cntToKeepSclIDs} toDelSclGIDs found to be active syllables:\",toKeepSclGIDsOfDels)\n",
    "    if cntToKeepSclIDs > 0:\n",
    "      #remove active syllables from the to delete syllables\n",
    "      newToDelSclIDs = [sclID for sclID in toDelSclIDs if 'scl:' + str(sclID) not in toKeepSclGIDsOfDels]\n",
    "      if len(newToDelSclIDs) + cntToKeepSclIDs != cntDelScl:\n",
    "        print(f\"WARNING: toDelSclGIDs count {cntDelScl} does not equal new count {len(newToDelSclIDs)} plus active count {cntToKeepSclIDs}\")\n",
    "        print(f\"aborting to mark syllables for delete {toDelSclIDs}\")\n",
    "        cntDelScl = 0\n",
    "      else:\n",
    "        toDelSclIDs = newToDelSclIDs\n",
    "        # delete\n",
    "        cntDelScl = len(toDelSclIDs)\n",
    "  myRSH.saveDataFrame(dfSyllablesToDel,\n",
    "                      outdir='output', \n",
    "                      filename=f\"linephysical_syllables_to_delete{dbname}\",\n",
    "                      extType=\"csv\")\n",
    "  myRSH.saveDataFrame(dfActiveSyllables,\n",
    "                      outdir='output', \n",
    "                      filename=f\"linephysical_syllables_to_keep{dbname}\",\n",
    "                      extType=\"csv\")\n",
    "  print(f\"Marking {cntDelScl} syllables for delete; lp sclids {toDelSclIDs}\")\n",
    "#  if cntDelScl > 0:\n",
    "#    deleteSyllableClusters(toDelSclIDs)\n",
    "else:\n",
    "  print(\"No line physical sequence syllables to process\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "Find and delete all segments attached only to syllables marked for delete\n",
    "'''\n",
    "textPhysSeqTermID = myRQC.getTermIDStrict('textphysical','sequencetype')\n",
    "linePhysSeqTermID = myRQC.getTermIDStrict('linephysical','textphysical')\n",
    "imgBaselineTermID = myRQC.getTermIDStrict('image','baselinetype')\n",
    "tagPaleographyTermID = myRQC.getTermIDStrict('paleography','tagtype')\n",
    "\n",
    "# Find all image segments attached to a syllable marked for delete\n",
    "queryFindSegmentsOfSyllablesToDelete = f\"\\\n",
    "  SELECT seg_id, dsc.scl_id AS scl_del, \\\n",
    "    dsc.scl_owner_id AS del_owner, \\\n",
    "    bln_id, bln_type_id, bln_owner_id, seg_owner_id, seg_image_pos, \\\n",
    "    dsc.scl_grapheme_ids AS grad, dsc.scl_owner_id \\\n",
    "  FROM segment \\\n",
    "  LEFT JOIN syllablecluster dsc ON dsc.scl_segment_id=seg_id \\\n",
    "  LEFT JOIN baseline ON bln_id=ANY(seg_baseline_ids) \\\n",
    "  WHERE dsc.scl_id IS NOT NULL AND dsc.scl_owner_id = 1 \\\n",
    "    AND seg_owner_id !=1 AND seg_image_pos IS NOT NULL \\\n",
    "    AND bln_type_id={imgBaselineTermID} \\\n",
    "  ORDER BY seg_owner_id, seg_id, dsc.scl_id;\\\n",
    "\"\n",
    "delSclSegIDs = []\n",
    "cntDelSclSegs = 0\n",
    "myRQC.query(queryFindSegmentsOfSyllablesToDelete)\n",
    "if myRQC.getResultCount() > 0:\n",
    "  dfDelSclSegments = pd.DataFrame(myRQC.getAllResults(), columns=myRQC.getColumnNames())\n",
    "  delSclSegIDs = pd.unique(sorted(list(dfDelSclSegments['seg_id'])))\n",
    "  myRSH.saveDataFrame(dfDelSclSegments,\n",
    "                      outdir='output', \n",
    "                      filename=f\"del_syllables_image_segments{dbname}\",\n",
    "                      extType=\"csv\")\n",
    "  cntDelSclSegs = len(delSclSegIDs)\n",
    "  print(f\"{cntDelSclSegs} segments attached to deleted encoding clusters:\",delSclSegIDs)\n",
    "\n",
    "\n",
    "if cntDelSclSegs > 0:\n",
    "  '''\n",
    "Find all image segments attached only to a syllable marked for delete\n",
    "  '''\n",
    "  queryFindImageSegmentsToDelete = f\"\\\n",
    "    SELECT seg_id, dsc.scl_id AS scl_del, sca.scl_id AS scl_act,\\\n",
    "        dsc.scl_owner_id AS del_owner, sca.scl_owner_id AS act_owner,\\\n",
    "        bln_id, bln_type_id, bln_owner_id, seg_image_pos,\\\n",
    "        dsc.scl_grapheme_ids AS grad, dsc.scl_owner_id,\\\n",
    "        sca.scl_owner_id, sca.scl_grapheme_ids AS graa \\\n",
    "    FROM segment \\\n",
    "    LEFT JOIN syllablecluster dsc ON dsc.scl_segment_id=seg_id \\\n",
    "    LEFT JOIN baseline ON bln_id=ANY(seg_baseline_ids) \\\n",
    "    LEFT JOIN syllablecluster sca ON sca.scl_segment_id=seg_id \\\n",
    "    LEFT JOIN sequence on CONCAT('seq:', sca.scl_id) = ANY(seq_entity_ids) \\\n",
    "    WHERE dsc.scl_id is not NULL AND dsc.scl_owner_id = 1 AND dsc.scl_id != sca.scl_id AND sca.scl_owner_id != 1 \\\n",
    "      AND seg_owner_id !=1 AND seg_image_pos is not NULL AND seq_owner_id = 1 AND seq_type_id = {linePhysSeqTermID} \\\n",
    "      AND bln_type_id={imgBaselineTermID} \\\n",
    "    ORDER BY seg_id, dsc.scl_id;\\\n",
    "  \"\n",
    "  myRQC.query(queryFindImageSegmentsToDelete)\n",
    "  if myRQC.getResultCount() > 0:\n",
    "    dfDelImageSegments = pd.DataFrame(myRQC.getAllResults(), columns=myRQC.getColumnNames())\n",
    "    toDelSegIDs = pd.unique(sorted(list(dfDelImageSegments['seg_id'])))\n",
    "    cntDelSegs = len(toDelSegIDs)\n",
    "    print(f\"{cntDelSegs} toDelSegIDs segments to delete:\",toDelSegIDs)\n",
    "    myRSH.saveDataFrame(dfDelImageSegments,\n",
    "                        outdir='output', \n",
    "                        filename=f\"del_syllable_segments_to_delete{dbname}\",\n",
    "                        extType=\"csv\")\n",
    "    print(f\"Marking {cntDelSegs} syllables for delete; lp sclids {toDelSegIDs}\")\n",
    "#    deleteSegments(toDelSegIDs)\n",
    "  else:\n",
    "    print(\"No image segments to delete found\")\n",
    "else:\n",
    "  print(\"No image segments to process\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "Find all syllableclusters that are 'marked for delete' that are tagged\n",
    "'''\n",
    "tagPaleographyTermID = myRQC.getTermIDStrict('paleography','tagtype')\n",
    "\n",
    "# Find all annotation with links to a syllable marked for delete\n",
    "queryFindAnnotationsWithSyllablesToRemove = f\"\\\n",
    "  SELECT ano_id, ano_type_id as tagID, ano_linkto_ids as links, \\\n",
    "         ARRAY_AGG(CONCAT('scl:',a.scl_id)) AS sclLinksToRemove \\\n",
    "  FROM annotation \\\n",
    "    LEFT JOIN \\\n",
    "      (SELECT scl_id \\\n",
    "      FROM syllablecluster \\\n",
    "      WHERE scl_owner_id = 1 \\\n",
    "        AND scl_id IN \\\n",
    "        (SELECT  DISTINCT(REPLACE(UNNEST(ano_linkto_ids),'scl:',''))::int as scl_id \\\n",
    "         FROM annotation \\\n",
    "         WHERE ano_owner_id != 1 \\\n",
    "           AND ano_type_id IN (SELECT trm_id \\\n",
    "                               FROM term \\\n",
    "                               WHERE trm_parent_id in (SELECT trm_id \\\n",
    "                                                       FROM term \\\n",
    "                                                       WHERE trm_parent_id = {tagPaleographyTermID}))\\\n",
    "           AND ano_linkto_ids[1] LIKE 'scl%' \\\n",
    "         ORDER BY scl_id) \\\n",
    "      ORDER BY scl_id) a ON CONCAT('scl:',a.scl_id) = ANY(ano_linkto_ids) \\\n",
    "  WHERE a.scl_id IS NOT null \\\n",
    "  GROUP BY ano_id; \\\n",
    "\"\n",
    "myRQC.query(queryFindAnnotationsWithSyllablesToRemove)\n",
    "if myRQC.getResultCount() > 0:\n",
    "  dfAnoWithDelScls = pd.DataFrame(myRQC.getAllResults(), columns=myRQC.getColumnNames())\n",
    "  myRSH.saveDataFrame(dfAnoWithDelScls,\n",
    "                      outdir='output', \n",
    "                      filename=f\"anoTags_linked_with_del_syllables{dbname}\",\n",
    "                      extType=\"csv\")\n",
    "  anoInfoWithDelScls = myRQC.getRowsAsIndexMultiDict(columnName = 'ano_id')\n",
    "  for anoID in anoInfoWithDelScls.keys():\n",
    "    anoInfo = anoInfoWithDelScls[anoID][0]\n",
    "    tag = myRQC.getTermCode(anoInfo['tagid'])\n",
    "    links = anoInfo['links']\n",
    "    sclLinksToRemove = anoInfo['scllinkstoremove']\n",
    "    print(f\" tag {tag} in ano {anoID} has {len(links)} links with {len(sclLinksToRemove)} to be removed\")\n",
    "    for sclGID in sclLinksToRemove:\n",
    "      links.remove(sclGID)\n",
    "    print(f\"tag {tag} now has {len(links)} links for updating anoID {anoID}\")\n",
    "#    myRQC.update(\"annotation\",{\"ano_linkto_ids\":\"{\"+','.join([str(i) for i in links])+\"}\"},{\"ano_id\":anoID})\n",
    "#    if myRQC.hasError():\n",
    "#      print(f\"Error while updating anoID {anoID} - {myRQC.getError()}\")\n",
    "#    else:\n",
    "#      print(f\"Update of tag {tag} (ano:{anoID}) was successful\")\n",
    "else:\n",
    "  print(\"No sclIDs linked to annoTag to be removed\")\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "97ae724bfa85b9b34df7982b8bb8c7216f435b92902d749e4263f71162bea840"
  },
  "kernelspec": {
   "display_name": "readadmin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
